{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a43d53f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2d48695",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_int(x):\n",
    "    return int(x, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4db2b479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Almost Done!\n"
     ]
    }
   ],
   "source": [
    "packet = pd.read_csv(\"./datasets/iot-network-intrusion-dataset_190919/Packets_integrated/UDP_flooding.txt\", sep=\"\\n\", header = None)\n",
    "packet[packet[0].str.contains(\"Frame \\(\")] = \"\\f\"\n",
    "packet[0] = packet[0].str[:53]\n",
    "packet = packet[0].str.split(\"  \", expand=True)\n",
    "packet = packet[[0, 1]]\n",
    "packet = pd.DataFrame(packet.to_string(header=None, index=False).split(\"\\f\"))\n",
    "print(\"Almost Done!\")\n",
    "packet[0]=packet[0].str.lstrip()\n",
    "packet[0] = packet[0].str.replace(\"\\n\", \" \")\n",
    "for _ in range(10):\n",
    "    packet[0] = packet[0].str.replace(\"  \", \" \")\n",
    "packet[0] = packet[0].str[:222]\n",
    "packet = packet[0].str.split(\" \", expand=True)\n",
    "packet=packet.fillna(\"00\")\n",
    "packet = packet.drop(columns=[0, 17, 34, 51, 68, 71])\n",
    "packet=packet.replace(\"\",\"00\")\n",
    "packet = packet.applymap(to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da03048f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "      <th>65</th>\n",
       "      <th>66</th>\n",
       "      <th>67</th>\n",
       "      <th>69</th>\n",
       "      <th>70</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>136</td>\n",
       "      <td>54</td>\n",
       "      <td>108</td>\n",
       "      <td>215</td>\n",
       "      <td>28</td>\n",
       "      <td>86</td>\n",
       "      <td>172</td>\n",
       "      <td>224</td>\n",
       "      <td>16</td>\n",
       "      <td>97</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>114</td>\n",
       "      <td>35</td>\n",
       "      <td>61</td>\n",
       "      <td>122</td>\n",
       "      <td>114</td>\n",
       "      <td>35</td>\n",
       "      <td>66</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>136</td>\n",
       "      <td>54</td>\n",
       "      <td>108</td>\n",
       "      <td>215</td>\n",
       "      <td>28</td>\n",
       "      <td>86</td>\n",
       "      <td>172</td>\n",
       "      <td>224</td>\n",
       "      <td>16</td>\n",
       "      <td>97</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>114</td>\n",
       "      <td>35</td>\n",
       "      <td>61</td>\n",
       "      <td>122</td>\n",
       "      <td>114</td>\n",
       "      <td>35</td>\n",
       "      <td>66</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>244</td>\n",
       "      <td>69</td>\n",
       "      <td>23</td>\n",
       "      <td>179</td>\n",
       "      <td>136</td>\n",
       "      <td>54</td>\n",
       "      <td>108</td>\n",
       "      <td>215</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>28</td>\n",
       "      <td>155</td>\n",
       "      <td>143</td>\n",
       "      <td>133</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>127</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>244</td>\n",
       "      <td>69</td>\n",
       "      <td>23</td>\n",
       "      <td>179</td>\n",
       "      <td>136</td>\n",
       "      <td>54</td>\n",
       "      <td>108</td>\n",
       "      <td>215</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>28</td>\n",
       "      <td>155</td>\n",
       "      <td>143</td>\n",
       "      <td>133</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>127</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>244</td>\n",
       "      <td>69</td>\n",
       "      <td>23</td>\n",
       "      <td>179</td>\n",
       "      <td>136</td>\n",
       "      <td>54</td>\n",
       "      <td>108</td>\n",
       "      <td>215</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>28</td>\n",
       "      <td>155</td>\n",
       "      <td>143</td>\n",
       "      <td>133</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>127</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1187109</th>\n",
       "      <td>136</td>\n",
       "      <td>54</td>\n",
       "      <td>108</td>\n",
       "      <td>215</td>\n",
       "      <td>28</td>\n",
       "      <td>86</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>244</td>\n",
       "      <td>69</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>246</td>\n",
       "      <td>28</td>\n",
       "      <td>162</td>\n",
       "      <td>168</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1187110</th>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>244</td>\n",
       "      <td>69</td>\n",
       "      <td>23</td>\n",
       "      <td>179</td>\n",
       "      <td>136</td>\n",
       "      <td>54</td>\n",
       "      <td>108</td>\n",
       "      <td>215</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>28</td>\n",
       "      <td>162</td>\n",
       "      <td>168</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1187111</th>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>244</td>\n",
       "      <td>69</td>\n",
       "      <td>23</td>\n",
       "      <td>179</td>\n",
       "      <td>136</td>\n",
       "      <td>54</td>\n",
       "      <td>108</td>\n",
       "      <td>215</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>28</td>\n",
       "      <td>162</td>\n",
       "      <td>168</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1187112</th>\n",
       "      <td>136</td>\n",
       "      <td>54</td>\n",
       "      <td>108</td>\n",
       "      <td>215</td>\n",
       "      <td>28</td>\n",
       "      <td>86</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>244</td>\n",
       "      <td>69</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>251</td>\n",
       "      <td>28</td>\n",
       "      <td>162</td>\n",
       "      <td>168</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1187113</th>\n",
       "      <td>136</td>\n",
       "      <td>54</td>\n",
       "      <td>108</td>\n",
       "      <td>215</td>\n",
       "      <td>28</td>\n",
       "      <td>86</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>244</td>\n",
       "      <td>69</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>251</td>\n",
       "      <td>28</td>\n",
       "      <td>162</td>\n",
       "      <td>168</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1187114 rows Ã— 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          1   2    3    4   5    6    7    8    9    10  ...  60  61   62  \\\n",
       "0        136  54  108  215  28   86  172  224   16   97  ...   5  10  114   \n",
       "1        136  54  108  215  28   86  172  224   16   97  ...   5  10  114   \n",
       "2          4  50  244   69  23  179  136   54  108  215  ...   8  10   28   \n",
       "3          4  50  244   69  23  179  136   54  108  215  ...   8  10   28   \n",
       "4          4  50  244   69  23  179  136   54  108  215  ...   8  10   28   \n",
       "...      ...  ..  ...  ...  ..  ...  ...  ...  ...  ...  ...  ..  ..  ...   \n",
       "1187109  136  54  108  215  28   86    4   50  244   69  ...   8  10    0   \n",
       "1187110    4  50  244   69  23  179  136   54  108  215  ...   8  10   28   \n",
       "1187111    4  50  244   69  23  179  136   54  108  215  ...   8  10   28   \n",
       "1187112  136  54  108  215  28   86    4   50  244   69  ...   8  10    0   \n",
       "1187113  136  54  108  215  28   86    4   50  244   69  ...   8  10    0   \n",
       "\n",
       "          63   64   65   66   67   69   70  \n",
       "0         35   61  122  114   35   66   50  \n",
       "1         35   61  122  114   35   66   50  \n",
       "2        155  143  133    0    0  127   71  \n",
       "3        155  143  133    0    0  127   71  \n",
       "4        155  143  133    0    0  127   71  \n",
       "...      ...  ...  ...  ...  ...  ...  ...  \n",
       "1187109    1   52  246   28  162  168   50  \n",
       "1187110  162  168   84    0    1   52  242  \n",
       "1187111  162  168   84    0    1   52  242  \n",
       "1187112    1   52  251   28  162  168   84  \n",
       "1187113    1   52  251   28  162  168   84  \n",
       "\n",
       "[1187114 rows x 66 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "packet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7fe7abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hjhhi\\anaconda3\\envs\\python3.6.8\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3072: DtypeWarning: Columns (0,1,5) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "label = pd.read_csv(\"./datasets/iot-network-intrusion-dataset_190919/Packets_integrated/UPD_flooding_attacked.csv\", header=None)\n",
    "index = label[0][1:].apply(int)\n",
    "label = np.zeros(len(packet))\n",
    "label[index] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf09d11a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "949283    1150643\n",
       "949284    1150644\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index[-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9e46742",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(237830, 949284)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(label[label==0]), len(label[label==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "025b0f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = packet, label\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e97e433b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 155347 samples, validate on 38837 samples\n",
      "Epoch 1/20\n",
      "155347/155347 [==============================] - 12s 79us/sample - loss: 1.1375 - accuracy: 0.8136 - val_loss: 0.5254 - val_accuracy: 0.8510\n",
      "Epoch 2/20\n",
      "155347/155347 [==============================] - 12s 77us/sample - loss: 0.5508 - accuracy: 0.8332 - val_loss: 0.3928 - val_accuracy: 0.8527\n",
      "Epoch 3/20\n",
      "155347/155347 [==============================] - 12s 76us/sample - loss: 0.4041 - accuracy: 0.8450 - val_loss: 0.3244 - val_accuracy: 0.8708\n",
      "Epoch 4/20\n",
      "155347/155347 [==============================] - 12s 77us/sample - loss: 0.3417 - accuracy: 0.8606 - val_loss: 0.4038 - val_accuracy: 0.8390\n",
      "Epoch 5/20\n",
      "155347/155347 [==============================] - 12s 77us/sample - loss: 0.3069 - accuracy: 0.8733 - val_loss: 0.3317 - val_accuracy: 0.8647\n",
      "Epoch 6/20\n",
      "155347/155347 [==============================] - 12s 76us/sample - loss: 0.2932 - accuracy: 0.8774 - val_loss: 0.2946 - val_accuracy: 0.8736\n",
      "Epoch 7/20\n",
      "155347/155347 [==============================] - 12s 77us/sample - loss: 0.2901 - accuracy: 0.8767 - val_loss: 0.3169 - val_accuracy: 0.8708\n",
      "Epoch 8/20\n",
      "155347/155347 [==============================] - 15s 95us/sample - loss: 0.2901 - accuracy: 0.8796 - val_loss: 0.2887 - val_accuracy: 0.8781\n",
      "Epoch 9/20\n",
      "155347/155347 [==============================] - 14s 90us/sample - loss: 0.2855 - accuracy: 0.8817 - val_loss: 0.2902 - val_accuracy: 0.8772\n",
      "Epoch 10/20\n",
      "155347/155347 [==============================] - 14s 91us/sample - loss: 0.2844 - accuracy: 0.8805 - val_loss: 0.2950 - val_accuracy: 0.8837\n",
      "Epoch 11/20\n",
      "155347/155347 [==============================] - 15s 95us/sample - loss: 0.2827 - accuracy: 0.8821 - val_loss: 0.2902 - val_accuracy: 0.8820\n",
      "Epoch 12/20\n",
      "155347/155347 [==============================] - 14s 90us/sample - loss: 0.2811 - accuracy: 0.8831 - val_loss: 0.2872 - val_accuracy: 0.8790\n",
      "Epoch 13/20\n",
      "155347/155347 [==============================] - 14s 90us/sample - loss: 0.2785 - accuracy: 0.8851 - val_loss: 0.2872 - val_accuracy: 0.8856\n",
      "Epoch 14/20\n",
      "155347/155347 [==============================] - 14s 90us/sample - loss: 0.2779 - accuracy: 0.8852 - val_loss: 0.2849 - val_accuracy: 0.8829\n",
      "Epoch 15/20\n",
      "155347/155347 [==============================] - 14s 90us/sample - loss: 0.2768 - accuracy: 0.8860 - val_loss: 0.2988 - val_accuracy: 0.8782\n",
      "Epoch 16/20\n",
      "155347/155347 [==============================] - 14s 90us/sample - loss: 0.2758 - accuracy: 0.8865 - val_loss: 0.2823 - val_accuracy: 0.8848\n",
      "Epoch 17/20\n",
      "155347/155347 [==============================] - 14s 90us/sample - loss: 0.2757 - accuracy: 0.8863 - val_loss: 0.2821 - val_accuracy: 0.8861\n",
      "Epoch 18/20\n",
      "155347/155347 [==============================] - 14s 90us/sample - loss: 0.2754 - accuracy: 0.8873 - val_loss: 0.2865 - val_accuracy: 0.8821\n",
      "Epoch 19/20\n",
      "155347/155347 [==============================] - 14s 90us/sample - loss: 0.2753 - accuracy: 0.8861 - val_loss: 0.2837 - val_accuracy: 0.8792\n",
      "Epoch 20/20\n",
      "155347/155347 [==============================] - 14s 90us/sample - loss: 0.2742 - accuracy: 0.8879 - val_loss: 0.2819 - val_accuracy: 0.8823\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(100, activation=\"relu\", input_shape=[X_train.shape[1]]),\n",
    "    keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "history = model.fit(X_train, y_train, epochs=20, validation_data = (X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e435cce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 949691 samples, validate on 237423 samples\n",
      "Epoch 1/20\n",
      "949691/949691 [==============================] - 75s 79us/sample - loss: 0.1487 - accuracy: 0.9750 - val_loss: 0.0874 - val_accuracy: 0.9785\n",
      "Epoch 2/20\n",
      "949691/949691 [==============================] - 93s 98us/sample - loss: 0.0869 - accuracy: 0.9784 - val_loss: 0.0850 - val_accuracy: 0.9785\n",
      "Epoch 3/20\n",
      "949691/949691 [==============================] - 93s 98us/sample - loss: 0.0858 - accuracy: 0.9785 - val_loss: 0.0864 - val_accuracy: 0.9785\n",
      "Epoch 4/20\n",
      "949691/949691 [==============================] - 93s 98us/sample - loss: 0.0853 - accuracy: 0.9785 - val_loss: 0.0874 - val_accuracy: 0.9785\n",
      "Epoch 5/20\n",
      "949691/949691 [==============================] - 80s 84us/sample - loss: 0.0851 - accuracy: 0.9785 - val_loss: 0.0842 - val_accuracy: 0.9785\n",
      "Epoch 6/20\n",
      "949691/949691 [==============================] - 78s 82us/sample - loss: 0.0849 - accuracy: 0.9785 - val_loss: 0.0848 - val_accuracy: 0.9785\n",
      "Epoch 7/20\n",
      "949691/949691 [==============================] - 75s 79us/sample - loss: 0.0849 - accuracy: 0.9785 - val_loss: 0.0838 - val_accuracy: 0.9785\n",
      "Epoch 8/20\n",
      "949691/949691 [==============================] - 85s 90us/sample - loss: 0.0848 - accuracy: 0.9785 - val_loss: 0.0842 - val_accuracy: 0.9785\n",
      "Epoch 9/20\n",
      "949691/949691 [==============================] - 81s 85us/sample - loss: 0.0848 - accuracy: 0.9785 - val_loss: 0.0868 - val_accuracy: 0.9785\n",
      "Epoch 10/20\n",
      "949691/949691 [==============================] - 81s 86us/sample - loss: 0.0848 - accuracy: 0.9785 - val_loss: 0.0842 - val_accuracy: 0.9785\n",
      "Epoch 11/20\n",
      "949691/949691 [==============================] - 83s 87us/sample - loss: 0.0849 - accuracy: 0.9785 - val_loss: 0.0860 - val_accuracy: 0.9785\n",
      "Epoch 12/20\n",
      "949691/949691 [==============================] - 81s 86us/sample - loss: 0.0847 - accuracy: 0.9785 - val_loss: 0.0841 - val_accuracy: 0.9785\n",
      "Epoch 13/20\n",
      "949691/949691 [==============================] - 82s 86us/sample - loss: 0.0847 - accuracy: 0.9785 - val_loss: 0.0847 - val_accuracy: 0.9785\n",
      "Epoch 14/20\n",
      "949691/949691 [==============================] - 81s 86us/sample - loss: 0.0847 - accuracy: 0.9785 - val_loss: 0.0842 - val_accuracy: 0.9785\n",
      "Epoch 15/20\n",
      "949691/949691 [==============================] - 79s 83us/sample - loss: 0.0847 - accuracy: 0.9785 - val_loss: 0.0869 - val_accuracy: 0.9785\n",
      "Epoch 16/20\n",
      "949691/949691 [==============================] - 70s 73us/sample - loss: 0.0846 - accuracy: 0.9785 - val_loss: 0.0851 - val_accuracy: 0.9785\n",
      "Epoch 17/20\n",
      "949691/949691 [==============================] - 76s 80us/sample - loss: 0.0847 - accuracy: 0.9785 - val_loss: 0.0851 - val_accuracy: 0.9785\n",
      "Epoch 18/20\n",
      "949691/949691 [==============================] - 83s 87us/sample - loss: 0.0845 - accuracy: 0.9785 - val_loss: 0.0843 - val_accuracy: 0.9785\n",
      "Epoch 19/20\n",
      "949691/949691 [==============================] - 83s 88us/sample - loss: 0.0846 - accuracy: 0.9785 - val_loss: 0.0872 - val_accuracy: 0.9785\n",
      "Epoch 20/20\n",
      "949691/949691 [==============================] - 73s 77us/sample - loss: 0.0846 - accuracy: 0.9785 - val_loss: 0.0851 - val_accuracy: 0.9785\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(100, activation=\"relu\", input_shape=[X_train.shape[1]]),\n",
    "    keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "history = model.fit(X_train, y_train, epochs=20, validation_data = (X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f3664ebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      benign       0.95      0.95      0.95     47306\n",
      "    attacked       0.99      0.99      0.99    190117\n",
      "\n",
      "    accuracy                           0.98    237423\n",
      "   macro avg       0.97      0.97      0.97    237423\n",
      "weighted avg       0.98      0.98      0.98    237423\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flood_pred = model.predict_classes(X_valid)\n",
    "result=[\"benign\", \"attacked\"]\n",
    "print(classification_report(y_valid,flood_pred , target_names=result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5f0535f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'dense/kernel:0' shape=(66, 100) dtype=float32, numpy=\n",
       " array([[-0.21548988, -0.06131569, -0.05593153, ...,  0.009556  ,\n",
       "          1.7233193 , -0.2308436 ],\n",
       "        [-0.18978657, -0.25972167,  0.10120087, ..., -0.0030753 ,\n",
       "         -2.4265988 , -0.25424433],\n",
       "        [-0.02546336, -0.03507623, -0.1180388 , ...,  0.00665484,\n",
       "         -1.0056187 , -0.19892313],\n",
       "        ...,\n",
       "        [-0.08734512, -0.02374357, -0.04575067, ..., -0.10786477,\n",
       "          1.9088019 ,  0.13243084],\n",
       "        [-0.08642702,  0.0873314 , -0.0180158 , ...,  0.05652766,\n",
       "          0.4187118 ,  0.0130941 ],\n",
       "        [-0.27137038,  0.19135252, -0.09057982, ...,  0.07734038,\n",
       "          0.3805156 ,  0.05727315]], dtype=float32)>,\n",
       " <tf.Variable 'dense/bias:0' shape=(100,) dtype=float32, numpy=\n",
       " array([-0.05285334, -0.12155698, -0.01935806, -0.6765026 , -0.07473051,\n",
       "        -0.0804761 , -0.05523553, -0.02441452, -0.08331953, -0.05623414,\n",
       "        -0.05350327, -0.17753392, -0.11969976, -0.0678602 , -0.05730273,\n",
       "        -0.07333406, -0.04360257, -0.57939464, -2.4601972 , -0.08342939,\n",
       "        -0.14104216, -0.07329584, -0.06722957, -0.05613611, -0.39566603,\n",
       "        -0.04010304, -0.06323139, -0.04910384, -0.13156791, -0.03946098,\n",
       "        -0.07604574, -0.15606816, -0.04732984, -0.05851566, -0.06189724,\n",
       "        -0.04253298, -0.07127142, -0.11995598, -0.05854547, -0.08577094,\n",
       "        -0.06565286, -0.03481858, -0.08412695, -0.06233163, -0.04710605,\n",
       "        -0.07071931, -0.11182201, -0.06393599, -0.05314156, -0.0800042 ,\n",
       "        -0.05379699, -0.16809028, -0.03011831, -0.05049848, -0.02985789,\n",
       "        -0.05642444, -0.04691522, -0.1281248 , -0.06024627, -0.04540259,\n",
       "        -0.09183598, -0.03679484, -0.06693669, -0.04748445, -0.771154  ,\n",
       "        -0.09454364, -0.10404436, -0.07088398, -0.07560409, -0.03594847,\n",
       "        -0.06337298, -0.14240228, -0.21818933, -0.04927079, -0.03548641,\n",
       "        -0.11141336, -0.08297627, -0.04439172, -0.05290455,  0.05203165,\n",
       "         0.        , -0.06280374, -0.04987565, -0.05591835, -0.05025938,\n",
       "        -0.06459942, -0.08478642, -0.04762486, -0.07855234, -0.08944964,\n",
       "        -0.2924378 , -0.10921231, -0.0884667 , -0.0504604 , -0.03813042,\n",
       "        -0.13406734, -0.03032617, -0.04558026, -2.0621455 , -0.0688019 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'dense_1/kernel:0' shape=(100, 1) dtype=float32, numpy=\n",
       " array([[-1.64596550e-02],\n",
       "        [ 7.86809996e-03],\n",
       "        [ 8.97035096e-03],\n",
       "        [-1.76338889e-02],\n",
       "        [ 1.13878176e-01],\n",
       "        [ 6.10514684e-03],\n",
       "        [ 1.44254655e-01],\n",
       "        [ 1.27818450e-01],\n",
       "        [ 2.06981506e-02],\n",
       "        [-2.22089863e-03],\n",
       "        [ 6.62549678e-03],\n",
       "        [-1.20275268e-04],\n",
       "        [-3.09867933e-02],\n",
       "        [-1.10851380e-03],\n",
       "        [-3.27992835e-03],\n",
       "        [ 7.76415542e-02],\n",
       "        [-6.83251247e-02],\n",
       "        [-2.55351309e-02],\n",
       "        [-2.76759602e-02],\n",
       "        [-2.14681569e-02],\n",
       "        [-2.31602751e-02],\n",
       "        [-1.63674110e-03],\n",
       "        [-1.07488759e-01],\n",
       "        [ 3.57514387e-03],\n",
       "        [-1.70712471e-02],\n",
       "        [ 5.87875396e-02],\n",
       "        [ 7.03695640e-02],\n",
       "        [-6.17907057e-03],\n",
       "        [ 2.21225363e-03],\n",
       "        [ 5.46251191e-04],\n",
       "        [-4.07658629e-02],\n",
       "        [-7.63873896e-03],\n",
       "        [-2.72927005e-02],\n",
       "        [-1.99068859e-02],\n",
       "        [ 1.11159412e-02],\n",
       "        [-1.54405147e-01],\n",
       "        [-4.36918475e-02],\n",
       "        [-3.05751991e-02],\n",
       "        [ 1.55835390e-01],\n",
       "        [ 1.34002352e-02],\n",
       "        [-8.32316354e-02],\n",
       "        [ 1.36504769e-01],\n",
       "        [ 8.26204941e-03],\n",
       "        [ 2.88801342e-02],\n",
       "        [ 1.24250920e-02],\n",
       "        [-3.58505337e-03],\n",
       "        [ 1.26663316e-03],\n",
       "        [ 1.65686801e-01],\n",
       "        [-3.09725199e-02],\n",
       "        [ 1.20679606e-02],\n",
       "        [-1.23283244e-03],\n",
       "        [-2.02266108e-02],\n",
       "        [ 3.75798084e-02],\n",
       "        [ 6.87990244e-03],\n",
       "        [-3.76671623e-03],\n",
       "        [ 1.15325555e-01],\n",
       "        [-2.70596356e-03],\n",
       "        [ 2.01318064e-03],\n",
       "        [ 7.30292080e-03],\n",
       "        [ 1.16445031e-03],\n",
       "        [-5.95569350e-02],\n",
       "        [ 1.17432334e-01],\n",
       "        [ 4.50231247e-02],\n",
       "        [-2.82810293e-02],\n",
       "        [-2.51719039e-02],\n",
       "        [ 5.65097202e-03],\n",
       "        [ 1.05939414e-02],\n",
       "        [-3.31866229e-03],\n",
       "        [ 9.44090716e-04],\n",
       "        [-9.55461264e-02],\n",
       "        [-1.17403762e-02],\n",
       "        [-6.49765925e-03],\n",
       "        [ 1.28409909e-02],\n",
       "        [ 6.10954352e-02],\n",
       "        [ 8.99738574e-04],\n",
       "        [ 9.62912943e-03],\n",
       "        [-2.19676699e-02],\n",
       "        [-7.16237584e-03],\n",
       "        [-8.03613756e-03],\n",
       "        [ 2.84322556e-02],\n",
       "        [ 1.71059579e-01],\n",
       "        [ 1.63239539e-02],\n",
       "        [ 1.15190625e-01],\n",
       "        [-1.23892985e-02],\n",
       "        [ 1.68492690e-01],\n",
       "        [-8.35532695e-02],\n",
       "        [ 3.59513913e-03],\n",
       "        [ 1.03844767e-02],\n",
       "        [-1.57605961e-03],\n",
       "        [ 5.46445977e-03],\n",
       "        [-2.58021653e-02],\n",
       "        [ 3.82543379e-03],\n",
       "        [ 3.24572902e-03],\n",
       "        [-1.20544014e-02],\n",
       "        [ 6.49450871e-04],\n",
       "        [-7.99327716e-03],\n",
       "        [ 7.25920871e-02],\n",
       "        [ 1.69534564e-01],\n",
       "        [-2.09360626e-02],\n",
       "        [ 8.14422220e-02]], dtype=float32)>,\n",
       " <tf.Variable 'dense_1/bias:0' shape=(1,) dtype=float32, numpy=array([-1.4979953], dtype=float32)>]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.trainable_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ae0e71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.6.8",
   "language": "python",
   "name": "python3.6.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
